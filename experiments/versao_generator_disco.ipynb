{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sensoriamento Espectral Inteligente para Coexistência em Mega-Constelações de Satélites LEO\n**Autor:** Lana Alves Vieira Gonzaga\n\n**Data:** Novembro de 2025\n\n**Descrição:** Este projeto implementa uma Rede Neural Convolucional (CNN) para classificar 24 tipos de modulação de rádio a partir do dataset RadioML 2018.01A. O objetivo é analisar o desempenho do modelo em diferentes condições de sinal-ruído (SNR). Esse tipo de modelo de classificação é utilizado como base para alocação dinâmica de espectro em sistemas de rádio cognitivo para comunicação eficiente de satélites. Algumas das tecnologias e funcionalidades utilizadas: TensorFlow, Keras, Python, HDF5, pipeline de dados otimizado, classificador CNN e agente cognitivo com detetecção híbrida.","metadata":{}},{"cell_type":"code","source":"# Instalação de Dependências\n\n!pip install kagglehub[pandas-datasets]\n\n!pip uninstall -y protobuf\n!pip install protobuf==3.20.3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport sys\nimport h5py\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nfrom IPython.display import FileLink\nimport seaborn as sns\nimport json\nimport warnings\nimport os\nimport kagglehub\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers, callbacks\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import load_model\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. Configuração do kaggle para download do dataset \"RadioML 2018.01A\":","metadata":{}},{"cell_type":"code","source":"# 2.1. Configuração da API do Kaggle, adaptada para o ambiente em que for executada.\n\ndef setup_kaggle_api():\n\n  !pip install -q kaggle\n\n  IN_COLAB = 'google.colab' in sys.modules\n\n  kaggle_json_path = Path.home() / '.kaggle' / 'kaggle.json'\n\n  if IN_COLAB:\n        print(\"Ambiente Google Colab detectado.\")\n        if not kaggle_json_path.exists():\n            print(\"Faça o upload do ficheiro kaggle.json.\")\n            from google.colab import files\n            uploaded = files.upload()\n\n            if 'kaggle.json' in uploaded:\n                print(\"kaggle.json recebido. Configurando.\")\n\n                kaggle_dir = Path.home() / '.kaggle'\n                kaggle_dir.mkdir(exist_ok=True, parents=True)\n\n                with open(kaggle_json_path, 'wb') as f:\n                    f.write(uploaded['kaggle.json'])\n            else:\n                print(\"Upload cancelado ou ficheiro incorreto.\")\n                return False\n\n  # Fora do colab.\n  else:\n        print(\"Ambiente local ou desconhecido detectado.\")\n\n        if not kaggle_json_path.exists():\n            print(f\"ERRO: Ficheiro kaggle.json não encontrado em '{kaggle_json_path}'.\")\n            print(\"Por favor, descarregue o seu token da API do Kaggle e coloque-o nesse local.\")\n            return False\n\n  !chmod 600 {kaggle_json_path}\n\nsetup_kaggle_api()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2.2. Download do dataset \"RadioML 2018.01A\".\n\ntry:\n    path = kagglehub.dataset_download(\"pinxau1000/radioml2018\")\n    print(f\"\\nDownload concluído. Os ficheiros estão em: '{path}'\")\n\n    print(\"\\nArquivos encontrados no diretório do dataset:\")\n    found_files = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirname, filename)\n            if file_path.endswith(('.h5', '.hdf5')):\n                found_files.append(file_path)\n                print(f\"  • {file_path}\")\n\n    if found_files:\n        HDF5_FILE_PATH = found_files[0]\n        print(f\"\\nCaminho do ficheiro HDF5 para carregar: '{HDF5_FILE_PATH}'\")\n    else:\n        print(\"\\nNenhum ficheiro HDF5 encontrado no diretório descarregado.\")\n\nexcept Exception as e:\n      print(f\"\\nOcorreu um erro durante o download: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2.3. Passar arquivo para o disco local\n\nimport os\nimport shutil\nimport time\n\nprint(\"COPIANDO ARQUIVO PARA DISCO LOCAL\")\n\nprint(f\"\\n Arquivo atual:\")\nprint(f\"   Caminho: {HDF5_FILE_PATH}\")\nprint(f\"   Tamanho: {os.path.getsize(HDF5_FILE_PATH) / 1e9:.2f} GB\")\n\n\nlocal_path = '/content/radioml_local.hdf5'\n\n\nif os.path.exists(local_path):\n    print(f\"\\n Arquivo local já existe: {local_path}\")\n    print(f\"   Tamanho: {os.path.getsize(local_path) / 1e9:.2f} GB\")\nelse:\n    print(f\"\\n Copiando para: {local_path}\")\n    print(\"   Isso vai levar alguns minutos.\")\n\n    start = time.time()\n    shutil.copy2(HDF5_FILE_PATH, local_path)\n    elapsed = time.time() - start\n\n    print(f\"   Cópia concluída em {elapsed/60:.1f} minutos.\")\n    print(f\"   Tamanho: {os.path.getsize(local_path) / 1e9:.2f} GB\")\n\n\nHDF5_FILE_PATH = local_path\nprint(f\"\\n Novo caminho: {HDF5_FILE_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3. Pré-processamento dos dados:","metadata":{}},{"cell_type":"code","source":"# 3.1. Divisão em índices das informações do dataset, para não sobrecarregar a RAM com o conjunto inteiro de dados de uma vez só.\n\nHDF5_FILE_PATH = '/content/radioml_local.hdf5'\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    total_samples = f['X'].shape[0]\n    num_classes = f['Y'].shape[1]\nprint(f\"Total de amostras no dataset: {total_samples}\")\nprint(f\"Número de classes de modulação: {num_classes}\")\n\nall_indices = np.arange(total_samples)\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    labels_for_stratify = f['Y'][:]\n\n# Primeiro split: 80% treino+validação / 20% teste.\nindices_temp, test_indices = train_test_split(\n    all_indices, test_size=0.2, random_state=42, stratify=labels_for_stratify\n)\n\nlabels_temp = labels_for_stratify[indices_temp]\n\n# Segundo split: divide treino+validação em 80% treino / 20% validação.\ntrain_indices, val_indices = train_test_split(\n    indices_temp, test_size=0.1 / (1 - 0.2), random_state=42, stratify=labels_temp\n)\n\nprint(f\"\\nNúmero de índices de treino: {len(train_indices)}\")\nprint(f\"Número de índices de validação: {len(val_indices)}\")\nprint(f\"Número de índices de teste: {len(test_indices)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3.2. Classe do gerador de dados e pré-processamento (one hot-enconding, normalização )\n\nclass RadioMLGenerator(keras.utils.Sequence):\n\n  def __init__(self, file_path, indices, batch_size, num_classes,\n             shuffle=True, augment=False, normalize=True, label_key='Y'):\n    self.indices = indices.copy()\n    self.batch_size = batch_size\n    self.num_classes = num_classes\n    self.shuffle = shuffle\n    self.augment = augment\n    self.normalize = normalize\n\n    self.file = h5py.File(file_path, 'r')\n\n    self.X_data = self.file['X']\n    self.Y_data = self.file['Y']\n\n    self.on_epoch_end()\n\n\n  def __len__(self):    \n        return int(np.ceil(len(self.indices) / self.batch_size))\n\n\n  def __getitem__(self, index):\n\n    start_idx = index * self.batch_size\n    end_idx = (index + 1) * self.batch_size\n    batch_indices = self.indices[start_idx:end_idx]\n\n    original_order = np.argsort(np.argsort(batch_indices))\n\n\n    batch_indices_sorted = np.sort(batch_indices)\n\n\n    X_batch = np.array(self.X_data[batch_indices_sorted])\n    Y_batch = np.array(self.Y_data[batch_indices_sorted])\n\n\n    X_batch = X_batch[original_order]\n    Y_batch = Y_batch[original_order]\n\n    X_batch = self._preprocess_signals(X_batch)\n\n\n    return X_batch, Y_batch\n\n\n    if self.normalize:\n        max_val = np.max(np.abs(X_batch), axis=(1, 2), keepdims=True)\n        X_batch = X_batch / (max_val + 1e-7)\n\n\n    return X_batch, Y_batch\n\n  def _preprocess_signals(self, X):  \n      if len(X.shape) == 2:\n            batch_size, total_samples = X.shape\n            timesteps = total_samples // 2\n            X = X.reshape(batch_size, timesteps, 2)\n\n      elif X.shape[1] == 2:\n            X = np.transpose(X, (0, 2, 1))\n\n      if self.normalize:\n            X = self._normalize_power(X)\n\n      if self.augment:\n            X = self._augment_signals(X)\n\n      return X.astype(np.float32)\n\n  def _normalize_power(self, X):    \n       X_normalized = np.zeros_like(X)\n\n       for i in range(X.shape[0]):    \n            signal = X[i]\n            power = np.sqrt(np.mean(signal[:, 0]**2 + signal[:, 1]**2))\n            X_normalized[i] = signal / (power + 1e-8)\n\n       return X_normalized\n\n  def _augment_signals(self, X):    \n      augmented = []\n\n      for i in range(X.shape[0]):\n            signal = X[i]\n            signal_complex = signal[:, 0] + 1j * signal[:, 1]\n\n            phase_shift = np.random.uniform(0, 2 * np.pi)\n            signal_rotated = signal_complex * np.exp(1j * phase_shift)\n\n            noise_level = 0.01\n            noise = noise_level * (np.random.randn(len(signal_rotated)) +\n                                   1j * np.random.randn(len(signal_rotated)))\n            signal_augmented = signal_rotated + noise\n\n            signal_iq = np.stack([signal_augmented.real, signal_augmented.imag], axis=-1)\n            augmented.append(signal_iq)\n\n      return np.array(augmented)\n\n  def on_epoch_end(self):\n        if self.shuffle:\n            np.random.shuffle(self.indices)\n\n  def __del__(self):\n        if hasattr(self, 'h5_file'):\n            try:\n                self.h5_file.close()\n                print(\"[INFO] Arquivo HDF5 fechado com sucesso\")\n            except:\n                pass","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3.3. Criação dos geradores de treino, validação e teste\n\nbatch_size = 1024\n\ndef create_generators(file_path, train_indices, val_indices, test_indices,\n                     batch_size=1024, num_classes=24):\n\n    train_gen = RadioMLGenerator(\n        file_path=HDF5_FILE_PATH,\n        indices=train_indices,\n        batch_size=batch_size,\n        num_classes=num_classes,\n        shuffle=True,\n        augment=True,\n        normalize=True\n    )\n\n    val_gen = RadioMLGenerator(\n        file_path=HDF5_FILE_PATH,\n        indices=val_indices,\n        batch_size=batch_size,\n        num_classes=num_classes,\n        shuffle=False,\n        augment=False,\n        normalize=True\n    )\n\n    test_gen = RadioMLGenerator(\n        file_path=HDF5_FILE_PATH,\n        indices=test_indices,\n        batch_size=batch_size,\n        num_classes=num_classes,\n        shuffle=False,\n        augment=False,\n        normalize=True\n    )\n\n    print(\"\\nGeradores criados:\")\n    print(f\"   Treino:    {len(train_gen)} batches\")\n    print(f\"   Validação: {len(val_gen)} batches\")\n    print(f\"   Teste:     {len(test_gen)} batches\")\n    print(\"=\"*80 + \"\\n\")\n\n\n    return train_gen, val_gen, test_gen\n\nbatch_size = 128\n\ntrain_generator, validation_generator, test_generator = create_generators(\n    file_path=HDF5_FILE_PATH,\n    train_indices=train_indices,\n    val_indices=val_indices,\n    test_indices=test_indices,\n    batch_size=batch_size,\n    num_classes=num_classes\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3.4. Visuzalização dos dados\n\ndef visualize_batch(generator, num_samples=4, figsize=(16, 10)):\n  if generator.num_classes == 24:\n        modulations = [                                                        \n            'OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK',\n            '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM',\n            '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC',\n            'FM', 'GMSK', 'OQPSK'\n        ]\n\n  else:\n        modulations = [f'Classe_{i}' for i in range(generator.num_classes)]\n\n  X_batch, Y_batch = generator[0]\n\n  fig = plt.figure(figsize=figsize)\n  gs = GridSpec(num_samples, 3, figure=fig, hspace=0.4, wspace=0.3)\n\n  print(\"=\"*80)\n  print(\"Visualização do batch\")\n  print(\"=\"*80)\n  print(f\"X shape: {X_batch.shape}, Y shape: {Y_batch.shape}\")\n  print(f\"X range: [{X_batch.min():.4f}, {X_batch.max():.4f}]\")\n  print(\"=\"*80 + \"\\n\")\n\n  for idx in range(min(num_samples, len(X_batch))):\n        signal = X_batch[idx]\n        label = Y_batch[idx]\n        class_idx = np.argmax(label)\n        mod_name = modulations[class_idx]\n\n        I, Q = signal[:, 0], signal[:, 1]\n        time_steps = np.arange(len(I))\n\n        ax1 = fig.add_subplot(gs[idx, 0])   # sinal no tempo\n        ax1.plot(time_steps, I, 'b-', alpha=0.7, linewidth=1, label='I')\n        ax1.plot(time_steps, Q, 'r-', alpha=0.7, linewidth=1, label='Q')\n        ax1.set_xlabel('Amostras')\n        ax1.set_ylabel('Amplitude')\n        ax1.set_title(f'{mod_name} - Sinal I/Q')\n        ax1.legend(loc='upper right', fontsize=8)\n        ax1.grid(True, alpha=0.3)\n\n        ax2 = fig.add_subplot(gs[idx, 1])   # constelação\n        ax2.scatter(I, Q, c=time_steps, cmap='viridis', s=10, alpha=0.6)\n        ax2.set_xlabel('I')\n        ax2.set_ylabel('Q')\n        ax2.set_title(f'{mod_name} - Constelação')\n        ax2.grid(True, alpha=0.3)\n        ax2.axis('equal')\n        circle = plt.Circle((0, 0), 1, color='gray', fill=False,\n                           linestyle='--', linewidth=1, alpha=0.5)\n        ax2.add_patch(circle)\n\n        ax3 = fig.add_subplot(gs[idx, 2])   # espectro\n        signal_complex = I + 1j * Q\n        fft_result = np.fft.fftshift(np.fft.fft(signal_complex))\n        power_spectrum = np.abs(fft_result)**2\n        freqs = np.fft.fftshift(np.fft.fftfreq(len(signal_complex)))\n        ax3.plot(freqs, 10*np.log10(power_spectrum + 1e-10), 'g-', linewidth=1)\n        ax3.set_xlabel('Frequência Normalizada')\n        ax3.set_ylabel('Potência (dB)')\n        ax3.set_title(f'{mod_name} - Espectro')\n        ax3.grid(True, alpha=0.3)\n\n        plt.tight_layout()\n\n        nome_arquivo = f'sinais_lote_exemplo.png'\n        plt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\n        print(f\"Imagem salva como: {nome_arquivo}\")\n\n        plt.savefig('figura_sinais.pdf', bbox_inches='tight') \n\n        plt.show()\n\n  print(\"\\nDistribuição de classes no batch:\")\n  class_distribution = np.argmax(Y_batch, axis=1)\n  unique, counts = np.unique(class_distribution, return_counts=True)\n  for cls, count in zip(unique, counts):\n        mod = modulations[cls]\n        print(f\"  {mod:15s}: {count:3d} ({count/len(Y_batch)*100:.1f}%)\")\n  print(\"=\"*80)\n\n\nvisualize_batch(train_generator)\nvisualize_batch(validation_generator)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4. Construção do classificador utlizando modelo de Rede Neural Convolucional (CNN)","metadata":{}},{"cell_type":"code","source":"# 4.1. Configurações e compilação do modelo\n\ndef create_radio_model(input_shape, num_classes):\n    inputs = layers.Input(shape=input_shape)\n\n\n    x = layers.Conv1D(64, kernel_size=8, padding='same', activation='relu')(inputs)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv1D(128, kernel_size=8, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv1D(256, kernel_size=8, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Conv1D(512, kernel_size=8, padding='same', activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.MaxPooling1D(pool_size=2)(x)\n    x = layers.Dropout(0.3)(x)\n\n    x = layers.Flatten()(x)\n\n    x = layers.Dense(128, activation='relu')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.5)(x)\n\n    outputs = layers.Dense(num_classes, activation='softmax')(x)\n\n    model = models.Model(inputs=inputs, outputs=outputs, name=\"RadioCNN\")\n    return model\n\nsample_x, _ = train_generator[0]\ninput_shape = sample_x.shape[1:]\nnum_classes = train_generator.num_classes\n\n\nmodel = create_radio_model(input_shape, num_classes)\nmodel.summary()\n\n\nopt = optimizers.Adam(learning_rate=0.001)\nmodel.compile(\n    loss='categorical_crossentropy',\n    metrics=['accuracy']\n)\n\nmy_callbacks = [\n    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1),\n    callbacks.ModelCheckpoint('melhor_modelo_radio.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n]\n\nprint(\"Modelo compilado e callbacks configurados.\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4.2. Treinamento\n\nprint(\"Iniciando o treinamento.\")\n\nBATCH_SIZE = 1024\n\ntrain_generator = RadioMLGenerator(HDF5_FILE_PATH, train_indices, BATCH_SIZE, num_classes, shuffle=True, normalize=True)\nvalidation_generator = RadioMLGenerator(HDF5_FILE_PATH, val_indices, BATCH_SIZE, num_classes, shuffle=False, normalize=True)\n\nsteps_per_epoch = len(train_generator)\nvalidation_steps = len(validation_generator)\n\nhistory = model.fit(\n    train_generator,\n    validation_data=validation_generator,\n    steps_per_epoch=steps_per_epoch,\n    validation_steps=validation_steps,\n    epochs=30,\n    callbacks=my_callbacks,\n    verbose=1\n)\n\nprint(\"Treinamento concluído.\")\n\ndef plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(14, 5))\n\n    # Gráfico de Acurácia\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'bo-', label='Treino')\n    plt.plot(epochs, val_acc, 'ro-', label='Validação')\n    plt.title('Acurácia de Treino e Validação')\n    plt.xlabel('Épocas')\n    plt.ylabel('Acurácia')\n    plt.legend()\n    plt.grid(True)\n\n    # Gráfico de Perda\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'bo-', label='Treino')\n    plt.plot(epochs, val_loss, 'ro-', label='Validação')\n    plt.title('Perda (Loss) de Treino e Validação')\n    plt.xlabel('Épocas')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    nome_arquivo = f'graficos_treino.png'\n    plt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\n    print(f\"Imagem salva como: {nome_arquivo}\")\n\n    plt.savefig('figura_sinais.pdf', bbox_inches='tight')\n\n    plt.show()\n\nplot_history(history)\n\nFileLink(r'melhor_modelo_radio.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4.3. Carregar e salvar modelo treinado\n\nprint(\"Carregando o modelo treinado do disco.\")\nmodel = load_model('melhor_modelo_radio.keras') \n\nprint(\"Modelo carregado com sucesso.\")\nmodel.summary()\n\ndisplay(FileLink(r'melhor_modelo_radio.keras'))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 4.4. Encontrar caminho do arquivo do modelo treinado e importar\n\nmodel_path = \"\"\n\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        if filename.endswith('.keras'):\n            full_path = os.path.join(dirname, filename)\n            print(f\" Encontrado: {full_path}\")\n            model_path = full_path\n\nif model_path:\n    print(f\"\\n O caminho para usar no load_model é:\\n'{model_path}'\")\nelse:\n    print(\"\\n Nenhum modelo encontrado.\")\n\ntry:\n    print(f\"Carregando modelo de: {model_path}\")\n    model = load_model(model_path)\n    print(\"Modelo recuperado com sucesso.\")\n    model.summary()\nexcept Exception as e:\n    print(f\"Erro ao carregar: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"5. Verificações","metadata":{}},{"cell_type":"code","source":"# 5.1. Gráfico de Acurácia vs SNR\n\nprint(\"Iniciando extração sincronizada de teste.\")\n\nall_y_true = []\nall_y_pred = []\nall_snr = []\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    \n    total_batches = len(test_generator)\n    \n    for i in range(total_batches):\n        start_idx = i * test_generator.batch_size\n        end_idx = min((i + 1) * test_generator.batch_size, len(test_generator.indices))\n        \n        batch_indices = test_generator.indices[start_idx:end_idx]\n        \n        batch_indices = sorted(batch_indices)\n        \n        X_batch = f['X'][batch_indices]\n        Y_batch = f['Y'][batch_indices]\n        Z_batch = f['Z'][batch_indices]\n        \n        max_val = np.max(np.abs(X_batch), axis=(1, 2), keepdims=True)\n        X_batch = X_batch / (max_val + 1e-7)\n        \n        pred_batch = model.predict(X_batch, verbose=0)\n        \n        all_y_true.append(np.argmax(Y_batch, axis=1)) \n        all_y_pred.append(np.argmax(pred_batch, axis=1))\n        all_snr.append(Z_batch)\n        \n        if i % 100 == 0:\n            print(f\"   Processado lote {i}/{total_batches}\")\n\ny_true_final = np.concatenate(all_y_true)\ny_pred_final = np.concatenate(all_y_pred)\nsnr_final = np.concatenate(all_snr)\n\nprint(\"Dados extraídos e alinhados.\")\n\n\nsnrs = sorted(list(np.unique(snr_final)))\nacc_by_snr = []\n\nfor snr in snrs:\n    mask = (snr_final == snr)[:, 0]\n    if np.sum(mask) > 0:\n        acc = np.mean(y_pred_final[mask] == y_true_final[mask])\n        acc_by_snr.append(acc)\n    else:\n        acc_by_snr.append(0)\n\nplt.figure(figsize=(10, 6))\nplt.plot(snrs, acc_by_snr, 'bo-', linewidth=2, label='Sua CNN')\nplt.axhline(y=1/24, color='r', linestyle='--', label='Aleatório (4%)')\nplt.title(f'Acurácia vs. SNR (Média Real: {np.mean(y_pred_final == y_true_final):.2%})')\nplt.xlabel('SNR (dB)')\nplt.ylabel('Acurácia')\nplt.legend()\nplt.grid(True)\n\nplt.savefig('acuracia_snr.png', dpi=300, bbox_inches='tight')\nprint(\"Imagem salva como 'acuracia_snr.png'\")\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5.2. Matriz de confusão\n\nprint(\"Iniciando extração sincronizada para Matriz de Confusão.\")\n\ny_true_list = []\ny_pred_list = []\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    total_batches = len(test_generator)\n    indices = test_generator.indices\n    batch_size = test_generator.batch_size\n    \n    for i in range(total_batches):\n        start = i * batch_size\n        end = min((i + 1) * batch_size, len(indices))\n        batch_idx = indices[start:end]\n        \n        batch_idx = sorted(batch_idx)\n        \n        X_batch = f['X'][batch_idx]\n        Y_batch = f['Y'][batch_idx]\n        \n        if hasattr(test_generator, 'normalize') and test_generator.normalize:\n            max_val = np.max(np.abs(X_batch), axis=(1, 2), keepdims=True)\n            X_batch = X_batch / (max_val + 1e-7)\n        \n        pred_batch = model.predict(X_batch, verbose=0)\n        \n        y_true_list.append(np.argmax(Y_batch, axis=1))      \n        y_pred_list.append(np.argmax(pred_batch, axis=1))   \n        \n        if i % 50 == 0:\n            print(f\"   -> Processado lote {i}/{total_batches}\")\n\n\ny_true_final = np.concatenate(y_true_list)\ny_pred_final = np.concatenate(y_pred_list)\n\nprint(\"Dados extraídos e alinhados.\")\n\ncm = confusion_matrix(y_true_final, y_pred_final)\n\ncm_norm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n\nif 'modulation_names' not in locals():\n    modulation_names = ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'FM', 'GFSK', \n                        'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM', '16APSK', '32APSK',\n                        '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM',\n                        '256QAM', 'AM-DSB-SC', 'AM-SSB-SC', 'OQPSK']\n\nplt.figure(figsize=(20, 20))\nsns.heatmap(cm_norm, annot=False, cmap='viridis', vmin=0, vmax=1,\n            xticklabels=modulation_names, \n            yticklabels=modulation_names)\n\nplt.title('Matriz de Confusão (Normalizada)', fontsize=15)\nplt.ylabel('Rótulo Verdadeiro', fontsize=12)\nplt.xlabel('Rótulo Previsto', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\n\nplt.savefig('matriz_confusao.png', dpi=300, bbox_inches='tight')\nprint(\"Imagem salva como 'matriz_confusao.png'\")\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5.3.Simulação de canais livres (ruído gaussiano)\n\nnoise_batch = np.random.normal(0, 1, size=(1000, 1024, 2)) \n\nmax_val = np.max(np.abs(noise_batch), axis=(1, 2), keepdims=True)\nnoise_batch = noise_batch / (max_val + 1e-7)\n\nx_real_batch, _ = test_gen_matrix[0] \n\nprint(\"Prevendo ruído.\")\npred_noise = model.predict(noise_batch, verbose=0)\nprint(\"Prevendo sinais reais.\")\npred_signal = model.predict(x_real_batch, verbose=0)\n\nconf_noise = np.max(pred_noise, axis=1)\nconf_signal = np.max(pred_signal, axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.hist(conf_noise, bins=50, alpha=0.7, label='Ruído (Canal Livre)', color='red')\nplt.hist(conf_signal, bins=50, alpha=0.7, label='Sinais Reais (Canal Ocupado)', color='blue')\nplt.title('Distribuição da Confiança do Modelo: Ruído vs. Sinais')\nplt.xlabel('Confiança (Probabilidade da classe vencedora)')\nplt.ylabel('Contagem')\nplt.legend()\nplt.grid(True, alpha=0.3)\n\nplt.savefig('confiança.png', dpi=300, bbox_inches='tight')\nprint(\"Imagem salva como 'confiança.png'\")\n\nplt.show()\n\nmean_noise_conf = np.mean(conf_noise)\nprint(f\"\\nConfiança média em Ruído: {mean_noise_conf:.4f}\")\nprint(f\"Confiança média em Sinais: {np.mean(conf_signal):.4f}\")\nprint(f\"--> Sugestão para o Agente: Considerar 'Livre' se confiança < {mean_noise_conf + 0.1:.2f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"6. Implementação de Modelo Heurístico Baseado em Regras (Rule-Based Heuristic), para alocação de espectro.","metadata":{}},{"cell_type":"code","source":"# 6.1. Funções auxiliares e configuração\n\nCONFIDENCE_THRESHOLD = 0.5 \n\ndef generate_noise(shape=(1024, 2)):\n    return np.random.normal(0, 0.005, size=shape)\n\nif 'modulation_names' not in locals():\n    modulation_names = ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'FM', 'GFSK', \n                        'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM', '16APSK', '32APSK',\n                        '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM',\n                        '256QAM', 'AM-DSB-SC', 'AM-SSB-SC', 'OQPSK']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.2. Classe do ambiente\n\nclass SpectrumEnvironment:\n    def __init__(self, num_channels, signal_generator, mod_names):\n        self.num_channels = num_channels\n        self.signal_generator = signal_generator \n        self.mod_names = mod_names\n        self.ground_truth = [] \n        \n    def update(self):\n        current_signals = []\n        self.ground_truth = []\n        \n        occupancy_rate = 0.6 \n\n        for i in range(self.num_channels):\n            if np.random.random() < occupancy_rate:\n               \n                rand_batch_idx = np.random.randint(0, len(self.signal_generator))\n                x_batch, y_batch = self.signal_generator[rand_batch_idx]\n                \n                rand_signal_idx = np.random.randint(0, len(x_batch))\n                signal = x_batch[rand_signal_idx]\n                \n                label_idx = np.argmax(y_batch[rand_signal_idx])\n                real_label = self.mod_names[label_idx]\n                \n                current_signals.append(signal)\n                self.ground_truth.append(real_label) \n                \n            else:\n                noise = generate_noise()\n                current_signals.append(noise)\n                self.ground_truth.append(\"Livre\")\n                \n        return np.array(current_signals)\n\n    def step(self, action_channel):\n        actual_state = self.ground_truth[action_channel]\n        \n        if actual_state == \"Livre\":\n            return 10, \"Transmissão em canal livre.\"\n        else:\n            return -50,\"Interferiu com um sinal {actual_state}\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.3. Classe do agente\n\nclass CognitiveAgent:\n    def __init__(self, model, mod_names):\n        self.model = model\n        self.mod_names = mod_names\n        self.energy_threshold = 0.01 \n        \n    def sense(self, signals):\n        sensed_results = []\n        \n        predictions = self.model.predict(signals, verbose=0)\n        \n        for i, signal in enumerate(signals):\n            energy = np.mean(np.abs(signal))\n            \n            if energy < self.energy_threshold:\n                sensed_results.append(\"Livre\")\n                continue\n    \n            pred = predictions[i]\n            predicted_idx = np.argmax(pred)\n            predicted_label = self.mod_names[predicted_idx]\n            \n            sensed_results.append(predicted_label)\n        \n        return sensed_results\n\n    def decide(self, sensed_results):\n        free_channels = [i for i, status in enumerate(sensed_results) if status == \"Livre\"]\n        \n        if not free_channels:\n            return None \n        \n        return np.random.choice(free_channels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.4. Execução\n\nNUM_CHANNELS = 5\nSTEPS = 15\n\nenv = SpectrumEnvironment(NUM_CHANNELS, validation_generator, modulation_names)\nagent = CognitiveAgent(model, modulation_names)\n\nprint(f\"Iniciando Simulação de Rádio Cognitivo ({NUM_CHANNELS} canais).\")\nprint(f\"Limiar de Confiança para 'Canal Livre': {CONFIDENCE_THRESHOLD}\")\nprint(\"-\" * 60)\n\ntotal_score = 0\n\nfor t in range(STEPS):\n    print(f\"\\n[Instante {t+1}/{STEPS}]\")\n    \n    spectrum_signals = env.update()\n    print(f\" Realidade:   {env.ground_truth}\")\n    \n    sensed_state = agent.sense(spectrum_signals)\n    print(f\" Agente Vê:   {sensed_state}\")\n    \n    chosen_channel = agent.decide(sensed_state)\n    \n    if chosen_channel is not None:\n        reward, msg = env.step(chosen_channel)\n        print(f\"  Ação: Transmitir no Canal {chosen_channel}\")\n        print(f\"  {msg}\")\n    else:\n        reward = 0\n        print(\" Ação: Aguardar (Nenhum canal livre seguro)\")\n        \n    total_score += reward\n\nprint(\"\\n\" + \"=\"*60)\nprint(f\" Pontuação Final: {total_score}\")\nif total_score > 0:\n    print(\"Conclusão: O agente conseguiu operar com sucesso e evitar a maioria das colisões.\")\nelse:\n    print(\"Conclusão: O agente teve muitas colisões. Talvez seja necessário ajustar o limiar.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}