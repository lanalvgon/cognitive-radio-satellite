{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2468162,"sourceType":"datasetVersion","datasetId":1493018}],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Sensoriamento Espectral Inteligente para Coexistência em Mega-Constelações de Satélites LEO\n**Autor:** Lana Alves Vieira Gonzaga\n\n**Data:** Novembro de 2025\n\n**Descrição:** Este projeto implementa uma Rede Neural Convolucional (CNN) para classificar 24 tipos de modulação de rádio a partir do dataset RadioML 2018.01A. O objetivo é analisar o desempenho do modelo em diferentes condições de sinal-ruído (SNR). Esse tipo de modelo de classificação é utilizado como base para alocação dinâmica de espectro em sistemas de rádio cognitivo para comunicação eficiente de satélites. Algumas das tecnologias e funcionalidades utilizadas: TensorFlow, Keras, Python, HDF5, pipeline de dados otimizado, classificador CNN e agente cognitivo com detetecção híbrida.","metadata":{}},{"cell_type":"markdown","source":"1. Imports e Instalações","metadata":{}},{"cell_type":"code","source":"# Instalação de Dependências\n# NOTA: Os comandos abaixo são específicos para configuração do ambiente Kaggle/Colab.\n# Se estiver a executar localmente, instale as dependências via 'requirements.txt'.\n\n# !pip install kagglehub[pandas-datasets]\n\n# Correção de conflito de versão do Protobuf (Específico para Kaggle)\n# !pip uninstall -y protobuf\n# !pip install protobuf==3.20.3","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Imports\n\nimport numpy as np\nimport sys\nimport h5py\nimport matplotlib.pyplot as plt\nfrom matplotlib.gridspec import GridSpec\nimport matplotlib.patches as mpatches\nfrom IPython.display import FileLink\nimport seaborn as sns\nimport json\nimport warnings\nimport os\nimport kagglehub\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, models, optimizers, callbacks\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.models import load_model\nfrom pathlib import Path\n\nwarnings.filterwarnings('ignore')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"2. Configuração do kaggle para download do dataset \"RadioML 2018.01A\":","metadata":{}},{"cell_type":"code","source":"# 2.1. Configuração da API do Kaggle, adaptada para o ambiente em que for executada.\n\ndef setup_kaggle_api():\n\n  !pip install -q kaggle\n\n  IN_COLAB = 'google.colab' in sys.modules\n\n  kaggle_json_path = Path.home() / '.kaggle' / 'kaggle.json'\n\n  if IN_COLAB:\n        print(\"Ambiente Google Colab detectado.\")\n        if not kaggle_json_path.exists():\n            print(\"Faça o upload do ficheiro kaggle.json.\")\n            from google.colab import files\n            uploaded = files.upload()\n\n            if 'kaggle.json' in uploaded:\n                print(\"kaggle.json recebido. Configurando.\")\n\n                kaggle_dir = Path.home() / '.kaggle'\n                kaggle_dir.mkdir(exist_ok=True, parents=True)\n\n                with open(kaggle_json_path, 'wb') as f:\n                    f.write(uploaded['kaggle.json'])\n            else:\n                print(\"Upload cancelado ou ficheiro incorreto.\")\n                return False\n\n  # Fora do colab.\n  else:\n        print(\"Ambiente local ou desconhecido detectado.\")\n\n        if not kaggle_json_path.exists():\n            print(f\"ERRO: Ficheiro kaggle.json não encontrado em '{kaggle_json_path}'.\")\n            print(\"Por favor, descarregue o seu token da API do Kaggle e coloque-o nesse local.\")\n            return False\n\n  !chmod 600 {kaggle_json_path}\n\nsetup_kaggle_api()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2.2. Download do dataset \"RadioML 2018.01A\".\n\ntry:\n    path = kagglehub.dataset_download(\"pinxau1000/radioml2018\")\n    print(f\"\\nDownload concluído. Os ficheiros estão em: '{path}'\")\n\n    print(\"\\nArquivos encontrados no diretório do dataset:\")\n    found_files = []\n    for dirname, _, filenames in os.walk(path):\n        for filename in filenames:\n            file_path = os.path.join(dirname, filename)\n            if file_path.endswith(('.h5', '.hdf5')):\n                found_files.append(file_path)\n                print(f\"  • {file_path}\")\n\n    if found_files:\n        HDF5_FILE_PATH = found_files[0]\n        print(f\"\\nCaminho do ficheiro HDF5 para carregar: '{HDF5_FILE_PATH}'\")\n    else:\n        print(\"\\nNenhum ficheiro HDF5 encontrado no diretório descarregado.\")\n\nexcept Exception as e:\n      print(f\"\\nOcorreu um erro durante o download: {e}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 2.3. Passar arquivo para o disco local\n\nimport os\nimport shutil\nimport time\n\nprint(\"COPIANDO ARQUIVO PARA DISCO LOCAL\")\n\nprint(f\"\\n Arquivo atual:\")\nprint(f\"   Caminho: {HDF5_FILE_PATH}\")\nprint(f\"   Tamanho: {os.path.getsize(HDF5_FILE_PATH) / 1e9:.2f} GB\")\n\n\nlocal_path = '/content/radioml_local.hdf5'\n\n\nif os.path.exists(local_path):\n    print(f\"\\n Arquivo local já existe: {local_path}\")\n    print(f\"   Tamanho: {os.path.getsize(local_path) / 1e9:.2f} GB\")\nelse:\n    print(f\"\\n Copiando para: {local_path}\")\n    print(\"   Isso vai levar alguns minutos.\")\n\n    start = time.time()\n    shutil.copy2(HDF5_FILE_PATH, local_path)\n    elapsed = time.time() - start\n\n    print(f\"   Cópia concluída em {elapsed/60:.1f} minutos.\")\n    print(f\"   Tamanho: {os.path.getsize(local_path) / 1e9:.2f} GB\")\n\n\nHDF5_FILE_PATH = local_path\nprint(f\"\\n Novo caminho: {HDF5_FILE_PATH}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"3. Pré-processamento dos dados:","metadata":{}},{"cell_type":"code","source":"# 3.1. Divisão em índices das informações do dataset, para não sobrecarregar a RAM com o conjunto inteiro de dados de uma vez só.\n\nHDF5_FILE_PATH = '/content/radioml_local.hdf5'\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    total_samples = f['X'].shape[0]\n    num_classes = f['Y'].shape[1]\nprint(f\"Total de amostras no dataset: {total_samples}\")\nprint(f\"Número de classes de modulação: {num_classes}\")\n\nall_indices = np.arange(total_samples)\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    labels_for_stratify = f['Y'][:]\n\n# Primeiro split: 80% treino+validação / 20% teste.\nindices_temp, test_indices = train_test_split(\n    all_indices, test_size=0.2, random_state=42, stratify=labels_for_stratify\n)\n\nlabels_temp = labels_for_stratify[indices_temp]\n\n# Segundo split: divide treino+validação em 80% treino / 20% validação.\ntrain_indices, val_indices = train_test_split(\n    indices_temp, test_size=0.1 / (1 - 0.2), random_state=42, stratify=labels_temp\n)\n\nprint(f\"\\nNúmero de índices de treino: {len(train_indices)}\")\nprint(f\"Número de índices de validação: {len(val_indices)}\")\nprint(f\"Número de índices de teste: {len(test_indices)}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Para otimizar o tempo de treinamento em ambiente de nuvem (Kaggle), optou-se por carregar um subconjunto estratificado de 1 milhão de amostras diretamente na RAM, utilizando precisão float16 para eficiência de memória.","metadata":{}},{"cell_type":"code","source":"# 3.2. Carregamento pra RAM e configuração do modelo CNN\n\n# 1. CONFIGURAÇÕES\n# (Confirme se este caminho está certo para o seu ambiente.)\n# Se usou o kagglehub antes, pode usar a variável 'path' ou 'HDF5_FILE_PATH' que ele gerou.\n\nNUM_SAMPLES_TO_LOAD = 1000000 \n\nprint(f\" Carregando {NUM_SAMPLES_TO_LOAD} amostras para a RAM.\")\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    X = f['X'][:NUM_SAMPLES_TO_LOAD]\n\n    print(\"Normalizando dados.\")\n\n    max_val = np.max(np.abs(X)) \n    X = X / max_val\n    \n    X = X.astype(np.float16)\n    \n    Y = f['Y'][:NUM_SAMPLES_TO_LOAD].astype(np.float16)\n\nprint(f\"Dados carregados. X shape: {X.shape}\")\n\ny_indices = np.argmax(Y, axis=1)\n\nprint(\"Dividindo em Treino e Validação.\")\nX_train, X_val, Y_train, Y_val = train_test_split(\n    X, Y, \n    test_size=0.3,\n    random_state=42, \n    stratify=y_indices\n)\n\ndel X, Y, y_indices\ngc.collect()\n\nprint(f\"Treino: {X_train.shape[0]} amostras | Validação: {X_val.shape[0]} amostras\")\n\ndef create_model():\n    model = keras.models.Sequential([\n        layers.Input(shape=(1024, 2)),\n        \n        layers.Conv1D(64, 8, padding='same', activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling1D(2),\n        \n        layers.Conv1D(128, 8, padding='same', activation='relu'),\n        layers.BatchNormalization(),\n        layers.MaxPooling1D(2),\n        \n        layers.Flatten(),\n        layers.Dense(128, activation='relu'),\n        layers.Dropout(0.5), \n        layers.Dense(24, activation='softmax')\n    ])\n    \n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    return model\n\nmodel = create_model()\nmodel.summary()\n\nbatch_size = 1024\n\nmy_callbacks = [\n    callbacks.EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True, verbose=1),\n    callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=0.00001, verbose=1),\n    callbacks.ModelCheckpoint('melhor_modelo_radio.keras', monitor='val_accuracy', save_best_only=True, verbose=1)\n]","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 3.3. Visuzalização dos dados\n\ndef visualize_ram_data(X, Y, num_samples=4, figsize=(16, 10)):\n    indices = np.random.choice(len(X), num_samples, replace=False)\n    \n    modulation_names = ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'FM', 'GFSK', \n                        'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM', '16APSK', '32APSK',\n                        '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM',\n                        '256QAM', 'AM-DSB-SC', 'AM-SSB-SC', 'OQPSK']\n\n    fig = plt.figure(figsize=figsize)\n    gs = GridSpec(num_samples, 3, figure=fig, hspace=0.4, wspace=0.3)\n\n    for i, idx in enumerate(indices):\n        signal = X[idx]\n        label_onehot = Y[idx]\n        \n        mod_name = modulation_names[np.argmax(label_onehot)]\n\n        I, Q = signal[:, 0], signal[:, 1]\n        time_steps = np.arange(len(I))\n\n        ax1 = fig.add_subplot(gs[i, 0])\n        ax1.plot(time_steps, I, 'b-', alpha=0.7, label='I')\n        ax1.plot(time_steps, Q, 'r-', alpha=0.7, label='Q')\n        ax1.set_title(f'{mod_name} - Tempo')\n        ax1.legend(loc='upper right', fontsize='small')\n        ax1.grid(True, alpha=0.3)\n\n        ax2 = fig.add_subplot(gs[i, 1])\n        ax2.scatter(I, Q, c=time_steps, cmap='viridis', s=5, alpha=0.6)\n        ax2.set_title(f'{mod_name} - Constelação')\n        ax2.axis('equal')\n        ax2.grid(True, alpha=0.3)\n\n        ax3 = fig.add_subplot(gs[i, 2])\n        signal_complex = I + 1j * Q\n        fft = np.fft.fftshift(np.fft.fft(signal_complex))\n        power = 10 * np.log10(np.abs(fft)**2 + 1e-10)\n        freqs = np.fft.fftshift(np.fft.fftfreq(len(signal_complex)))\n        ax3.plot(freqs, power, 'g-')\n        ax3.set_title(f'{mod_name} - Espectro')\n        ax3.grid(True, alpha=0.3)\n\n    plt.tight_layout()\n    plt.savefig('amostras_sinais_ram.png', dpi=150)\n    plt.show()\n\nvisualize_ram_data(X_train, Y_train)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"4. Treinamento do Modelo","metadata":{}},{"cell_type":"code","source":"# 4.1. Treinamento\n\nprint(\"Iniciando o treinamento.\")\n\nBATCH_SIZE = 1024\n\nhistory = model.fit(\n    x=X_train,\n    y=Y_train,\n    validation_data=(X_val, Y_val), \n    batch_size=1024,\n    epochs=15,\n    callbacks=my_callbacks,\n    verbose=1\n)\n\nprint(\"Treinamento concluído.\")\n\nimport matplotlib.pyplot as plt\n\ndef plot_history(history):\n    acc = history.history['accuracy']\n    val_acc = history.history['val_accuracy']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n    epochs = range(1, len(acc) + 1)\n\n    plt.figure(figsize=(14, 5))\n\n    # Gráfico de Acurácia\n    plt.subplot(1, 2, 1)\n    plt.plot(epochs, acc, 'bo-', label='Treino')\n    plt.plot(epochs, val_acc, 'ro-', label='Validação')\n    plt.title('Acurácia de Treino e Validação')\n    plt.xlabel('Épocas')\n    plt.ylabel('Acurácia')\n    plt.legend()\n    plt.grid(True)\n\n    # Gráfico de Perda\n    plt.subplot(1, 2, 2)\n    plt.plot(epochs, loss, 'bo-', label='Treino')\n    plt.plot(epochs, val_loss, 'ro-', label='Validação')\n    plt.title('Perda (Loss) de Treino e Validação')\n    plt.xlabel('Épocas')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.grid(True)\n\n    nome_arquivo = f'graficos_treino.png'\n    plt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\n    print(f\"Imagem salva como: {nome_arquivo}\")\n\n    plt.savefig('figura_sinais.pdf', bbox_inches='tight')\n\n    plt.show()\n\nplot_history(history)\n\nfrom IPython.display import FileLink\n\nFileLink(r'melhor_modelo_radio.keras')","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"5. Verificações","metadata":{}},{"cell_type":"code","source":"# 5.1. Gráfico de Acurácia vs SNR\n\nwith h5py.File(HDF5_FILE_PATH, 'r') as f:\n    Y_full = f['Y'][:NUM_SAMPLES_TO_LOAD]\n    Z_full = f['Z'][:NUM_SAMPLES_TO_LOAD]\n\ny_indices_full = np.argmax(Y_full, axis=1)\n\n_, Z_test_aligned, _, _ = train_test_split(\n    Z_full, Y_full, \n    test_size=0.3, \n    random_state=42, \n    stratify=y_indices_full\n)\n\nprint(\"Gerando previsões.\")\ny_pred_prob = model.predict(X_val, verbose=0)\ny_pred_classes = np.argmax(y_pred_prob, axis=1)\ny_true_classes = np.argmax(Y_val, axis=1)\n\nsnrs = sorted(list(np.unique(Z_test_aligned)))\nacc_by_snr = []\n\nfor snr in snrs:\n    if Z_test_aligned.ndim > 1:\n        mask = (Z_test_aligned == snr)[:, 0]\n    else:\n        mask = (Z_test_aligned == snr)\n        \n    if np.sum(mask) > 0:\n        acc = np.mean(y_pred_classes[mask] == y_true_classes[mask])\n        acc_by_snr.append(acc)\n    else:\n        acc_by_snr.append(0)\n\nplt.figure(figsize=(10, 6))\nplt.plot(snrs, acc_by_snr, 'bo-', linewidth=2, label='Sua CNN (RAM)')\nplt.axhline(y=1/24, color='r', linestyle='--', label='Aleatório (4%)')\nplt.title(f'Acurácia vs. SNR (Média Global: {np.mean(y_pred_classes == y_true_classes):.2%})')\nplt.xlabel('SNR (dB)')\nplt.ylabel('Acurácia')\nplt.grid(True)\nplt.legend()\nplt.savefig('acuracia_snr.png', dpi=300)\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5.2. Matriz de confusão\n\nprint(\"Gerando matriz de confusão.\")\n\nmodulation_names = [\n    'OOK', '4ASK', '8ASK', 'BPSK', 'QPSK', '8PSK', '16PSK', '32PSK',\n    '16APSK', '32APSK', '64APSK', '128APSK', '16QAM', '32QAM', '64QAM',\n    '128QAM', '256QAM', 'AM-SSB-WC', 'AM-SSB-SC', 'AM-DSB-WC', 'AM-DSB-SC',\n    'FM', 'GMSK', 'OQPSK'\n]\n\ncm = confusion_matrix(y_true_classes, y_pred_classes)\n\nclasses_presentes_indices = np.where(cm.sum(axis=1) > 0)[0]\n\ncm_filtered = cm[np.ix_(classes_presentes_indices, classes_presentes_indices)]\n\ncm_norm = cm_filtered.astype('float') / cm_filtered.sum(axis=1)[:, np.newaxis]\n\nmy_modulations = [modulation_names[i] for i in classes_presentes_indices]\n\n\nplt.figure(figsize=(12, 10))\nsns.heatmap(cm_norm, annot=True, fmt='.2f', cmap='viridis',\n            xticklabels=my_modulations,\n            yticklabels=my_modulations)\n\nplt.title('Matriz de Confusão (Classes Treinadas)', fontsize=16)\nplt.ylabel('Rótulo Verdadeiro', fontsize=12)\nplt.xlabel('Rótulo Previsto', fontsize=12)\nplt.xticks(rotation=45, ha='right')\nplt.yticks(rotation=0)\n\nplt.savefig('matriz_confusao_final.png', dpi=300, bbox_inches='tight')\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 5.3. Simulação de canais livres (ruído gaussiano) - Análise de confiança\n\nprint(\"Análise de Confiança: Ruído vs. Sinais Reais\")\n\nnoise_batch = np.random.normal(0, 1, size=(1000, 1024, 2))\nmax_val = np.max(np.abs(noise_batch), axis=(1, 2), keepdims=True)\nnoise_batch = noise_batch / (max_val + 1e-7)\n\nx_real_batch = X_val[:1000]\n\nprint(\"Prevendo ruído.\")\npred_noise = model.predict(noise_batch, verbose=0)\nprint(\"Prevendo sinais reais.\")\npred_signal = model.predict(x_real_batch, verbose=0)\n\nconf_noise = np.max(pred_noise, axis=1)\nconf_signal = np.max(pred_signal, axis=1)\n\nplt.figure(figsize=(10, 6))\nplt.hist(conf_noise, bins=50, alpha=0.7, label='Ruído (Canal Livre)', color='red')\nplt.hist(conf_signal, bins=50, alpha=0.7, label='Sinais Reais (Ocupado)', color='blue')\nplt.title('Por que precisamos de Energia? (IA tem excesso de confiança no ruído)')\nplt.xlabel('Confiança do Modelo (0 a 1)')\nplt.ylabel('Contagem')\nplt.legend()\nplt.grid(True, alpha=0.3)\nplt.show()\n\nprint(f\"Confiança média no Ruído: {np.mean(conf_noise):.4f}\")\nprint(\"Conclusão: A IA confunde ruído normalizado com sinal. O Agente precisará de um filtro de Energia.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"6. Implementação de Modelo Heurístico Baseado em Regras (Rule-Based Heuristic), para alocação de espectro.","metadata":{}},{"cell_type":"code","source":"# 6.1. Funções auxiliares e configuração\n\nCONFIDENCE_THRESHOLD = 0.5 \n\ndef generate_noise(shape=(1024, 2)):\n    return np.random.normal(0, 0.005, size=shape)\n\nif 'modulation_names' not in locals():\n    modulation_names = ['8PSK', 'AM-DSB', 'AM-SSB', 'BPSK', 'CPFSK', 'FM', 'GFSK', \n                        'PAM4', 'QAM16', 'QAM64', 'QPSK', 'WBFM', '16APSK', '32APSK',\n                        '64APSK', '128APSK', '16QAM', '32QAM', '64QAM', '128QAM',\n                        '256QAM', 'AM-DSB-SC', 'AM-SSB-SC', 'OQPSK']","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.2. Classe do ambiente\n\nimport numpy as np\n\nclass SpectrumEnvironment:\n    def __init__(self, num_channels, X_source, Y_source, mod_names):\n        self.num_channels = num_channels\n        self.X_source = X_source \n        self.Y_source = Y_source \n        self.mod_names = mod_names\n        self.ground_truth = []\n        \n    def update(self):\n        current_signals = []\n        self.ground_truth = []\n        \n        occupancy_rate = 0.6 \n\n        for i in range(self.num_channels):\n            if np.random.random() < occupancy_rate:\n \n                rand_idx = np.random.randint(0, len(self.X_source))\n                \n                signal = self.X_source[rand_idx]\n                label_onehot = self.Y_source[rand_idx]\n                \n                label_idx = np.argmax(label_onehot)\n                real_label = self.mod_names[label_idx]\n                \n                current_signals.append(signal)\n                self.ground_truth.append(real_label)\n            else:\n                noise = np.random.normal(0, 0.01, size=(1024, 2))\n                current_signals.append(noise)\n                self.ground_truth.append(\"Livre\")\n                \n        return np.array(current_signals)\n\n    def step(self, action_channel):\n        actual_state = self.ground_truth[action_channel]\n        if actual_state == \"Livre\":\n            return 10, \"Sucesso.\"\n        else:\n            return -50, f\" Colisão ({actual_state})\"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.3. Classe do agente\n\nclass CognitiveAgent:\n    def __init__(self, model, mod_names):\n        self.model = model\n        self.mod_names = mod_names\n        self.energy_threshold = 0.01 \n        \n    def sense(self, signals):\n        sensed_results = []\n        \n        predictions = self.model.predict(signals, verbose=0)\n        \n        for i, signal in enumerate(signals):\n            energy = np.mean(np.abs(signal))\n            \n            if energy < self.energy_threshold:\n                sensed_results.append(\"Livre\")\n                continue\n    \n            pred = predictions[i]\n            predicted_idx = np.argmax(pred)\n            predicted_label = self.mod_names[predicted_idx]\n            \n            sensed_results.append(predicted_label)\n        \n        return sensed_results\n\n    def decide(self, sensed_results):\n        free_channels = [i for i, status in enumerate(sensed_results) if status == \"Livre\"]\n        \n        if not free_channels:\n            return None \n        \n        return np.random.choice(free_channels)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# 6.4. Execução\n\nNUM_CHANNELS = 5\nSTEPS = 50 \n\nenv = SpectrumEnvironment(NUM_CHANNELS, X_val, Y_val, modulation_names)\nagent = CognitiveAgent(model, modulation_names)\n\nhistory_actions = []\nhistory_results = []\n\nprint(f\"Rodando simulação de {STEPS} passos para gerar gráfico.\")\n\nfor t in range(STEPS):\n    signals = env.update()\n    \n    sensed = agent.sense(signals)\n    action = agent.decide(sensed)\n    \n    if action is not None:\n        reward, msg = env.step(action)\n        result_type = \"Sucesso\" if reward > 0 else \"Colisão\"\n        history_actions.append((t, action))\n        history_results.append(result_type)\n    else:\n        history_actions.append((t, -1)) \n        history_results.append(\"Espera\")\n\nplt.figure(figsize=(15, 6))\n\ncolors = {\"Sucesso\": \"green\", \"Colisão\": \"red\", \"Espera\": \"gray\"}\nmarkers = {\"Sucesso\": \"o\", \"Colisão\": \"X\", \"Espera\": \"s\"}\n\nfor i, (step, channel) in enumerate(history_actions):\n    res = history_results[i]\n    \n    y_pos = channel if channel != -1 else -0.8\n    \n    plt.scatter(step, y_pos, color=colors[res], marker=markers[res], s=100, zorder=3)\n    \n    if channel != -1:\n        plt.vlines(step, -0.8, channel, color='gray', linestyle=':', alpha=0.3)\n\nplt.title('Timeline da Simulação: Alocação Dinâmica de Espectro', fontsize=16)\nplt.xlabel('Tempo (Passos da Simulação)', fontsize=12)\nplt.ylabel('Canal de Frequência', fontsize=12)\n\nplt.yticks([-0.8, 0, 1, 2, 3, 4], [\"Fila de\\nEspera\", \"Ch 0\", \"Ch 1\", \"Ch 2\", \"Ch 3\", \"Ch 4\"])\nplt.ylim(-1.5, 4.5)\nplt.grid(True, axis='x', alpha=0.3)\n\nlegend_patches = [\n    mpatches.Patch(color='green', label='Transmissão Sucesso (Canal Livre)'),\n    mpatches.Patch(color='red', label='Colisão (Interferência)'),\n    mpatches.Patch(color='gray', label='Agente Aguardou (Sem canais)')\n]\nplt.legend(handles=legend_patches, loc='upper right')\n\nnome_arquivo = 'resultado_simulacao.png'\nplt.savefig(nome_arquivo, dpi=300, bbox_inches='tight')\nprint(f\"Gráfico salvo como: {nome_arquivo}\")\n\nplt.show()","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}